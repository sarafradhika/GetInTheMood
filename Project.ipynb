{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# GetInTheMood 1.0\n",
    "# Project by Ishan Khurjekar and Radhika Saraf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import*\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.tag import CRFTagger\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# To eliminate stop words \n",
    "\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extracting data from .htm webpages \n",
    "\n",
    "def lyrics(input_files):\n",
    "\n",
    "    song_lyrics = []\n",
    "    \n",
    "    for fileno in input_files:\n",
    "        with open(fileno) as html_doc:\n",
    "            soup = BeautifulSoup(html_doc, 'html.parser')\n",
    "        texts = []\n",
    "    \n",
    "        # Look  for the 'p' element - this will change depending on the format of the website \n",
    "        for elem in soup.find_all(\"p\"):\n",
    "        \n",
    "            # This label is particular to the chosen website\n",
    "            if elem.attrs == {u'class': [u'verse']}:\n",
    "                lyrics = elem.text.lower()\n",
    "                tokens = word_tokenize(lyrics)\n",
    "                for word in tokens:\n",
    "                    texts.append(word)\n",
    "        song_lyrics.append(texts)\n",
    "    \n",
    "    return song_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def dictionary(train_lyrics):\n",
    "    \n",
    "## Parts of speech tagging \n",
    "    tagged = []\n",
    "    \n",
    "    for doc in train_lyrics:\n",
    "        tagged.append(nltk.pos_tag(doc,tagset='universal'))\n",
    "        \n",
    "## Tag the training data with the two labels : 'happy' and 'sad'\n",
    "# This is done based on the fact that the author perceives the chosen songs as either 'happy' or 'sad'\n",
    "\n",
    "    docs = []\n",
    "\n",
    "    for doc in range(4,8):\n",
    "        texts = []\n",
    "        for (word,label) in tagged[doc]:\n",
    "            if word not in stopWords:\n",
    "                if label != '.' and label != 'PRT' and label != 'X':\n",
    "                    texts.append((word,'happy'))\n",
    "        docs.append(texts)\n",
    "\n",
    "    for doc in range(4):\n",
    "        texts = []\n",
    "        for (word,label) in tagged[doc]:\n",
    "            if word not in stopWords:\n",
    "                if label != '.' and label != 'PRT' and label != 'X':\n",
    "                    texts.append((word,'sad'))\n",
    "        docs.append(texts)\n",
    "        \n",
    "## Create a mood dictionary from the most frequently occuring words in the happy/sad songs\n",
    "\n",
    "    fdist = FreqDist(docs[0])\n",
    "    for doc in docs:\n",
    "        fdist_temp = FreqDist(doc)\n",
    "        fdist |= fdist_temp\n",
    "    mood = fdist.most_common(80)\n",
    "\n",
    "    happy = []\n",
    "    sad = []\n",
    "\n",
    "    for ((word,label),count) in mood:\n",
    "        if word not in stopWords:\n",
    "            if label == 'happy':\n",
    "                happy.append(word)\n",
    "            if label == 'sad':\n",
    "                sad.append(word)\n",
    "                \n",
    "# Eliminating labeling bias\n",
    "\n",
    "    if len(happy) > len(sad):\n",
    "        happy = happy[0:len(sad)]\n",
    "    if len(sad) > len(happy):\n",
    "        sad = sad[0:len(happy)]\n",
    "        \n",
    "    return happy,sad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def brute_force_label(docs,happy,sad):\n",
    "    \n",
    "    labelled_docs = []\n",
    "    for doc in docs:\n",
    "        texts = []\n",
    "        for word in doc:\n",
    "            if word in happy:\n",
    "                label = 'happy'\n",
    "                couplet = (word,label)\n",
    "            elif word in sad:\n",
    "                label = 'sad'\n",
    "                couplet = (word,label)\n",
    "            else:\n",
    "                label = 'I'\n",
    "                couplet = (word,label)\n",
    "            texts.append(couplet)\n",
    "        labelled_docs.append(texts)\n",
    "        \n",
    "    return labelled_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluation(docs,test_truths):\n",
    "    tagger_out = []\n",
    "\n",
    "    for doc in docs:\n",
    "    \n",
    "# Using the CRF for labelling\n",
    "        tagger_out.append(ct.tag(doc))\n",
    "\n",
    "## Creating the inputs to run the classification report\n",
    "    \n",
    "    y_pred = []\n",
    "    for doc in test_truths:\n",
    "        for (word,label) in doc:\n",
    "            y_pred.append(label)\n",
    "    y_test = []\n",
    "    for doc in tagger_out:\n",
    "        for (word,label) in doc:\n",
    "            y_test.append(label)\n",
    "            \n",
    "# Create a mapping of labels to indices\n",
    "    labels = {\"happy\" : 0, \"sad\" : 1, \"I\" : 2}\n",
    "\n",
    "# Convert the sequences of tags into a 1-dimensional array\n",
    "    predictions = np.array([labels[tag] for tag in y_pred])\n",
    "    truths = np.array([labels[tag] for tag in y_test])\n",
    "\n",
    "# Print out the classification report\n",
    "    print(classification_report(\n",
    "        truths, predictions,\n",
    "        target_names=[\"happy\",\"sad\",'I']))\n",
    "\n",
    "    return tagger_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mood_calculator(song_lyrics):\n",
    "\n",
    "    happy_count = 0\n",
    "    sad_count = 0\n",
    "    which_list = []\n",
    "    \n",
    "    for doc in song_lyrics:\n",
    "        for (word,label) in doc:\n",
    "            if label == 'happy':\n",
    "                happy_count = happy_count + 1\n",
    "            elif label == 'sad':\n",
    "                sad_count = sad_count + 1\n",
    "        mood_ratio = sad_count/happy_count\n",
    "        \n",
    "#Predicting if the song should go to a happy list or a sad list \n",
    "    \n",
    "        if mood_ratio < 1 :\n",
    "            which_list.append('happy')\n",
    "        else:\n",
    "            which_list.append('sad')\n",
    "            \n",
    "    return which_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      happy       1.00      0.50      0.67         4\n",
      "        sad       0.96      1.00      0.98        22\n",
      "          I       1.00      1.00      1.00       634\n",
      "\n",
      "avg / total       1.00      1.00      0.99       660\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Webpages stored as HTML only : from metrolyrics.com\n",
    "train_files = ['myself.htm','summer.htm','cry.htm','stop.htm','celebrate.htm','happy.htm','world.htm','doremi.htm']\n",
    "\n",
    "train_lyrics = lyrics(train_files)\n",
    "\n",
    "[happy,sad] = dictionary(train_lyrics)\n",
    "\n",
    "## Using the dictionary as reference label each word in the song again as either happy or sad\n",
    "\n",
    "training_docs = brute_force_label(train_lyrics,happy,sad)\n",
    "\n",
    "## Train the CRF using this data\n",
    "\n",
    "ct = CRFTagger()\n",
    "train_data = training_docs\n",
    "ct.train(train_data,'model.crf.tagger')\n",
    "ct.set_model_file('model.crf.tagger')\n",
    "\n",
    "## Extract data for test files\n",
    "\n",
    "test_files = ['rolling.htm']\n",
    "\n",
    "test_lyrics = lyrics(test_files)\n",
    "test_truth = brute_force_label(test_lyrics,happy,sad)\n",
    "\n",
    "tagged_lyrics = evaluation(test_lyrics,test_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('rolling.htm', 'sad')]\n"
     ]
    }
   ],
   "source": [
    "# Songs classified as happy or sad\n",
    "print(zip(test_files,mood_calculator(tagged_lyrics)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      happy       1.00      0.99      1.00       437\n",
      "        sad       0.92      0.99      0.96       182\n",
      "          I       1.00      0.99      1.00      2511\n",
      "\n",
      "avg / total       0.99      0.99      0.99      3130\n",
      "\n",
      "[('myself.htm', 'sad'), ('summer.htm', 'sad'), ('cry.htm', 'sad'), ('stop.htm', 'sad'), ('celebrate.htm', 'happy'), ('happy.htm', 'happy'), ('world.htm', 'happy'), ('doremi.htm', 'happy')]\n"
     ]
    }
   ],
   "source": [
    "# Confirm the accuracy by using the CRF tagger to relabel the training documents\n",
    "\n",
    "test_files = ['myself.htm','summer.htm','cry.htm','stop.htm','celebrate.htm','happy.htm','world.htm','doremi.htm']\n",
    "\n",
    "test_lyrics = lyrics(test_files)\n",
    "test_truth = brute_force_label(test_lyrics,happy,sad)\n",
    "\n",
    "tagged_lyrics = evaluation(test_lyrics,test_truth)\n",
    "\n",
    "print(zip(test_files,mood_calculator(tagged_lyrics)))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
